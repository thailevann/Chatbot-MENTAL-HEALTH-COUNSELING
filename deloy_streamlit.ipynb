{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9rH1mO09k-e",
        "outputId": "d4b712c8-f1d8-4e77-a11e-19b4c3ae9842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: hugchat==0.0.8 in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hugchat==0.0.8) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from hugchat==0.0.8) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat==0.0.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat==0.0.8) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat==0.0.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat==0.0.8) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U loralib\n",
        "!pip install -q -U einops\n",
        "!pip install hugchat==0.0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahPOHZgF-byU",
        "outputId": "6a19b07b-c55f-4b9f-f364-3c3353bdc001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.37.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting replicate\n",
            "  Downloading replicate-0.31.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.8.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.2)\n",
            "Downloading streamlit-1.37.1-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading replicate-0.31.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, h11, pydeck, httpcore, gitdb, httpx, gitpython, replicate, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 pydeck-0.9.1 replicate-0.31.0 smmap-5.0.1 streamlit-1.37.1 tenacity-8.5.0 watchdog-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MZn9hOEi92px"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CZUaosEiCyfU"
      },
      "outputs": [],
      "source": [
        "# Tạo và ghi nội dung vào tệp secrets.toml\n",
        "with open(\"secrets.toml\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "REPLICATE_API_TOKEN = \"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\"\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaR9Z2GM-gVf",
        "outputId": "e335e207-8508-4d72-b8f1-1308f4dde10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import replicate\n",
        "import os\n",
        "import json\n",
        "import os\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "\n",
        "from pprint import pprint\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset, Dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# App title\n",
        "st.set_page_config(page_title=\"💬 Vinallama Mental Health Chatbot\")\n",
        "\n",
        "\n",
        "# Store LLM generated responses\n",
        "if \"messages\" not in st.session_state.keys():\n",
        "    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Bạn đang cảm thấy thế nào?\"}]\n",
        "\n",
        "# Display or clear chat messages\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.write(message[\"content\"])\n",
        "\n",
        "def clear_chat_history():\n",
        "    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Bạn đang cảm thấy thế nào?\"}]\n",
        "st.sidebar.button('Clear Chat History', on_click=clear_chat_history)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer():\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    PEFT_MODEL = \"thailevann/vinallama-mental-health_1\"\n",
        "    config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
        "    if not config.base_model_name_or_path:\n",
        "        config.base_model_name_or_path = \"vilm/vinallama-7b-chat\"\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        config.base_model_name_or_path,\n",
        "        return_dict=True,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        token=\"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\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = PeftModel.from_pretrained(model, PEFT_MODEL)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# Tải mô hình và tokenizer\n",
        "model, tokenizer = load_model_and_tokenizer()\n",
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 512\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = model.config.pad_token_id\n",
        "generation_config.eos_token_id = model.config.eos_token_id\n",
        "generation_config.no_repeat_ngram_size=3\n",
        "generation_config.do_sample = True       # Sử dụng sampling\n",
        "\n",
        "# Function for generating LLaMA2 response. Refactored from https://github.com/a16z-infra/llama2-chatbot\n",
        "def generate_llama2_response(prompt_input):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    string_dialogue = \"<|im_start|>system Bạn là một chuyên gia về tham vấn sức khỏe tâm thần. Bạn sẽ nhận câu hỏi của người bệnh, hãy trả lời hoặc đưa ra lời khuyên dành cho họ.\"\n",
        "    for dict_message in st.session_state.messages:\n",
        "        if dict_message[\"role\"] == \"user\":\n",
        "            string_dialogue += \"<|im_start|>user \\n ### Câu hỏi: \" + dict_message[\"content\"] + \"\\n\\n\"\n",
        "        else:\n",
        "            string_dialogue += \"### Câu trả lời: <|im_start|>assistant\" + dict_message[\"content\"] + \"\\n\\n\"\n",
        "\n",
        "    prompt = f\"{string_dialogue} ### Câu trả lời: <|im_start|>assistant \".strip()\n",
        "\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    complete_response = response\n",
        "    complete_response =  complete_response.split(\"<|im_start|> assistant\")[-1]\n",
        "    return complete_response\n",
        "\n",
        "# User-provided prompt\n",
        "if prompt := st.chat_input():\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(prompt)\n",
        "\n",
        "# Generate a new response if last message is not from assistant\n",
        "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = generate_llama2_response(prompt)\n",
        "            placeholder = st.empty()\n",
        "            full_response = ''\n",
        "            for item in response:\n",
        "                full_response += item\n",
        "                placeholder.markdown(full_response)\n",
        "            placeholder.markdown(full_response)\n",
        "    message = {\"role\": \"assistant\", \"content\": full_response}\n",
        "    st.session_state.messages.append(message)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nA127UZK-4m7"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYB4XWubAYMt",
        "outputId": "4f095229-ba7c-4352-bfd3-16fb4dacfb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqk8mBThAg49",
        "outputId": "c2a31693-5634-431c-84c2-488b7814f238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken \"2ifVdnJFoUTBBsPfiVisg8BMBJx_4AykwsTw4CahysQDqKFpt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9lk2U8xAW4U",
        "outputId": "01a8192b-fc87-43c8-cded-b9cb515ab525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://7f21-34-125-175-62.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wn4wDZ8kDzRU"
      },
      "outputs": [],
      "source": [
        "os.environ['REPLICATE_API_TOKEN'] = \"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\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6bCG5bDAdEk",
        "outputId": "af6f229e-8ffa-4dbb-86b8-ea4535d219ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\radapter_config.json:   0% 0.00/725 [00:00<?, ?B/s]\radapter_config.json: 100% 725/725 [00:00<00:00, 4.74MB/s]\n",
            "config.json: 100% 709/709 [00:00<00:00, 6.76MB/s]\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 89.0MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 21.0M/4.97G [00:00<00:25, 193MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 62.9M/4.97G [00:00<00:17, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 105M/4.97G [00:00<00:15, 305MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 147M/4.97G [00:00<00:15, 315MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 178M/4.97G [00:00<00:16, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.97G [00:00<00:15, 302MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 262M/4.97G [00:00<00:15, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 294M/4.97G [00:00<00:15, 302MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 325M/4.97G [00:01<00:15, 294MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 367M/4.97G [00:01<00:15, 299MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 409M/4.97G [00:01<00:15, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 451M/4.97G [00:01<00:14, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 493M/4.97G [00:01<00:14, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 535M/4.97G [00:01<00:14, 308MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 566M/4.97G [00:01<00:14, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 598M/4.97G [00:01<00:14, 305MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 640M/4.97G [00:02<00:13, 309MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 671M/4.97G [00:02<00:15, 271MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 703M/4.97G [00:02<00:16, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 734M/4.97G [00:02<00:16, 262MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 765M/4.97G [00:02<00:16, 262MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 797M/4.97G [00:02<00:15, 265MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 828M/4.97G [00:02<00:15, 265MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.97G [00:02<00:15, 265MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 891M/4.97G [00:03<00:15, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 923M/4.97G [00:03<00:15, 254MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 954M/4.97G [00:03<00:15, 255MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 986M/4.97G [00:03<00:15, 262MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.02G/4.97G [00:03<00:15, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.05G/4.97G [00:03<00:14, 267MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.08G/4.97G [00:03<00:14, 270MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.11G/4.97G [00:03<00:13, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.14G/4.97G [00:04<00:13, 279MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.17G/4.97G [00:04<00:13, 284MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.21G/4.97G [00:04<00:13, 285MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.24G/4.97G [00:04<00:12, 288MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.27G/4.97G [00:04<00:13, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.30G/4.97G [00:04<00:13, 281MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.33G/4.97G [00:04<00:12, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.36G/4.97G [00:04<00:12, 290MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.39G/4.97G [00:04<00:12, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.43G/4.97G [00:05<00:13, 271MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.46G/4.97G [00:05<00:15, 227MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.49G/4.97G [00:05<00:14, 245MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.52G/4.97G [00:05<00:13, 258MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.55G/4.97G [00:05<00:12, 273MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.58G/4.97G [00:05<00:12, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.97G [00:05<00:11, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.65G/4.97G [00:05<00:11, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.69G/4.97G [00:06<00:10, 302MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.72G/4.97G [00:06<00:10, 305MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.97G [00:06<00:10, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.78G/4.97G [00:06<00:10, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.81G/4.97G [00:06<00:10, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.85G/4.97G [00:06<00:10, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.88G/4.97G [00:06<00:10, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.92G/4.97G [00:06<00:10, 305MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.97G [00:06<00:09, 303MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.98G/4.97G [00:06<00:09, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.01G/4.97G [00:07<00:09, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.04G/4.97G [00:07<00:09, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.08G/4.97G [00:07<00:09, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.11G/4.97G [00:07<00:09, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.15G/4.97G [00:07<00:09, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.18G/4.97G [00:07<00:09, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.21G/4.97G [00:07<00:12, 227MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.24G/4.97G [00:08<00:14, 191MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.28G/4.97G [00:08<00:15, 170MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.30G/4.97G [00:08<00:16, 165MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.97G [00:08<00:15, 166MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.35G/4.97G [00:08<00:14, 184MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.97G [00:08<00:12, 202MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.41G/4.97G [00:08<00:11, 219MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.44G/4.97G [00:09<00:10, 231MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.47G/4.97G [00:09<00:10, 236MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.51G/4.97G [00:09<00:10, 227MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.54G/4.97G [00:09<00:10, 237MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.57G/4.97G [00:09<00:19, 124MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.97G [00:10<00:19, 123MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.61G/4.97G [00:10<00:20, 114MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.63G/4.97G [00:10<00:21, 110MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.65G/4.97G [00:10<00:23, 100MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.68G/4.97G [00:10<00:17, 131MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.72G/4.97G [00:11<00:13, 161MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.75G/4.97G [00:11<00:11, 191MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.78G/4.97G [00:11<00:10, 216MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.82G/4.97G [00:11<00:08, 243MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.85G/4.97G [00:11<00:08, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.88G/4.97G [00:11<00:07, 268MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.97G [00:11<00:07, 280MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.96G/4.97G [00:11<00:06, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.99G/4.97G [00:11<00:06, 285MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.02G/4.97G [00:12<00:06, 292MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.05G/4.97G [00:12<00:06, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.08G/4.97G [00:12<00:07, 251MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.11G/4.97G [00:12<00:07, 252MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.15G/4.97G [00:12<00:06, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.18G/4.97G [00:12<00:06, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.21G/4.97G [00:12<00:08, 212MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.24G/4.97G [00:13<00:07, 219MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.27G/4.97G [00:13<00:07, 234MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.30G/4.97G [00:13<00:06, 243MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.33G/4.97G [00:13<00:06, 254MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.37G/4.97G [00:13<00:06, 257MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.40G/4.97G [00:13<00:06, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.43G/4.97G [00:13<00:05, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.46G/4.97G [00:13<00:05, 267MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.49G/4.97G [00:13<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.97G [00:14<00:05, 275MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.55G/4.97G [00:14<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.59G/4.97G [00:14<00:04, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.62G/4.97G [00:14<00:04, 276MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.65G/4.97G [00:14<00:04, 283MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.68G/4.97G [00:14<00:04, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.71G/4.97G [00:14<00:04, 279MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.74G/4.97G [00:14<00:04, 275MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.77G/4.97G [00:15<00:04, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.81G/4.97G [00:15<00:04, 257MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.84G/4.97G [00:15<00:04, 226MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.87G/4.97G [00:15<00:04, 234MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.90G/4.97G [00:15<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.93G/4.97G [00:15<00:04, 253MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.97G [00:15<00:03, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 4.00G/4.97G [00:15<00:03, 268MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.97G [00:16<00:03, 275MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.06G/4.97G [00:16<00:03, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.09G/4.97G [00:16<00:03, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.12G/4.97G [00:16<00:03, 280MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.15G/4.97G [00:16<00:02, 280MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.18G/4.97G [00:16<00:02, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.22G/4.97G [00:16<00:02, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.25G/4.97G [00:16<00:02, 294MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.29G/4.97G [00:16<00:02, 299MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.33G/4.97G [00:17<00:02, 307MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.36G/4.97G [00:17<00:01, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.39G/4.97G [00:17<00:01, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.42G/4.97G [00:17<00:01, 305MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.46G/4.97G [00:17<00:01, 301MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.49G/4.97G [00:17<00:02, 233MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.52G/4.97G [00:17<00:02, 193MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.55G/4.97G [00:18<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.58G/4.97G [00:18<00:01, 226MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.97G [00:18<00:01, 241MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.65G/4.97G [00:18<00:01, 253MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.68G/4.97G [00:18<00:01, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.71G/4.97G [00:18<00:00, 274MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.74G/4.97G [00:18<00:00, 283MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.77G/4.97G [00:18<00:00, 284MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.81G/4.97G [00:18<00:00, 295MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.84G/4.97G [00:19<00:00, 292MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.88G/4.97G [00:19<00:00, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.91G/4.97G [00:19<00:00, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.97G/4.97G [00:19<00:00, 256MB/s]\n",
            "Downloading shards:  33% 1/3 [00:19<00:39, 19.78s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 31.5M/4.95G [00:00<00:16, 303MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 62.9M/4.95G [00:00<00:15, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 105M/4.95G [00:00<00:15, 314MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 147M/4.95G [00:00<00:15, 314MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 189M/4.95G [00:00<00:15, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 231M/4.95G [00:00<00:14, 332MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 273M/4.95G [00:00<00:14, 333MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 315M/4.95G [00:00<00:13, 335MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 357M/4.95G [00:01<00:13, 342MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 398M/4.95G [00:01<00:13, 338MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 440M/4.95G [00:01<00:13, 338MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 482M/4.95G [00:01<00:13, 337MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 524M/4.95G [00:01<00:13, 336MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 566M/4.95G [00:01<00:13, 335MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 608M/4.95G [00:01<00:12, 340MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 650M/4.95G [00:01<00:12, 337MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 692M/4.95G [00:02<00:12, 331MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 734M/4.95G [00:02<00:12, 326MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 776M/4.95G [00:02<00:12, 334MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 818M/4.95G [00:02<00:12, 326MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 860M/4.95G [00:02<00:12, 329MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 902M/4.95G [00:02<00:12, 321MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 944M/4.95G [00:02<00:12, 314MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 986M/4.95G [00:03<00:12, 314MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.03G/4.95G [00:03<00:12, 319MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.07G/4.95G [00:03<00:12, 318MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.11G/4.95G [00:03<00:12, 312MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.14G/4.95G [00:03<00:18, 202MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.17G/4.95G [00:03<00:17, 217MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.21G/4.95G [00:03<00:15, 235MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.24G/4.95G [00:04<00:15, 241MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.27G/4.95G [00:04<00:14, 254MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.30G/4.95G [00:04<00:13, 265MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.33G/4.95G [00:04<00:13, 275MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.36G/4.95G [00:04<00:13, 273MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.39G/4.95G [00:04<00:15, 223MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/4.95G [00:04<00:14, 243MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.46G/4.95G [00:04<00:13, 260MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.49G/4.95G [00:05<00:12, 272MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/4.95G [00:05<00:11, 297MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.56G/4.95G [00:05<00:11, 286MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.59G/4.95G [00:05<00:12, 278MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.63G/4.95G [00:05<00:11, 283MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.66G/4.95G [00:05<00:11, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.70G/4.95G [00:05<00:10, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.73G/4.95G [00:05<00:10, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.76G/4.95G [00:05<00:10, 303MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.80G/4.95G [00:06<00:10, 313MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.85G/4.95G [00:06<00:09, 328MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.89G/4.95G [00:06<00:09, 320MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.93G/4.95G [00:06<00:09, 323MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.97G/4.95G [00:06<00:09, 323MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.01G/4.95G [00:06<00:09, 319MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.06G/4.95G [00:06<00:09, 317MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.10G/4.95G [00:06<00:09, 314MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.13G/4.95G [00:07<00:09, 309MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.16G/4.95G [00:07<00:09, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.20G/4.95G [00:07<00:08, 313MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.23G/4.95G [00:07<00:10, 249MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.26G/4.95G [00:07<00:10, 257MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.30G/4.95G [00:07<00:09, 269MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.33G/4.95G [00:07<00:09, 274MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.37G/4.95G [00:07<00:09, 286MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.40G/4.95G [00:08<00:08, 288MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.43G/4.95G [00:08<00:08, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.46G/4.95G [00:08<00:09, 260MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.50G/4.95G [00:08<00:09, 263MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.54G/4.95G [00:08<00:08, 277MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.57G/4.95G [00:08<00:08, 283MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.60G/4.95G [00:08<00:08, 281MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.63G/4.95G [00:08<00:08, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.67G/4.95G [00:09<00:07, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.72G/4.95G [00:09<00:07, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.75G/4.95G [00:09<00:07, 306MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.78G/4.95G [00:09<00:07, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.81G/4.95G [00:09<00:07, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.85G/4.95G [00:09<00:06, 312MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/4.95G [00:09<00:06, 318MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.94G/4.95G [00:09<00:07, 274MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.97G/4.95G [00:10<00:07, 271MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.01G/4.95G [00:10<00:06, 286MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.05G/4.95G [00:10<00:06, 298MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.09G/4.95G [00:10<00:06, 307MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.14G/4.95G [00:10<00:05, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.17G/4.95G [00:10<00:05, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.20G/4.95G [00:10<00:05, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.23G/4.95G [00:10<00:05, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.27G/4.95G [00:11<00:05, 308MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.31G/4.95G [00:11<00:05, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.36G/4.95G [00:11<00:04, 321MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.40G/4.95G [00:11<00:04, 330MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.44G/4.95G [00:11<00:04, 332MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.48G/4.95G [00:11<00:04, 323MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.52G/4.95G [00:11<00:04, 324MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.57G/4.95G [00:11<00:04, 333MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.61G/4.95G [00:12<00:04, 328MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.65G/4.95G [00:12<00:04, 323MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.69G/4.95G [00:12<00:04, 309MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.72G/4.95G [00:12<00:03, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.75G/4.95G [00:12<00:03, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.79G/4.95G [00:12<00:03, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.82G/4.95G [00:12<00:03, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.85G/4.95G [00:12<00:03, 298MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.88G/4.95G [00:12<00:03, 294MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.92G/4.95G [00:13<00:03, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.95G/4.95G [00:13<00:03, 303MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 3.98G/4.95G [00:13<00:03, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.03G/4.95G [00:13<00:02, 308MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.06G/4.95G [00:13<00:02, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.09G/4.95G [00:13<00:02, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.12G/4.95G [00:13<00:02, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.15G/4.95G [00:13<00:02, 291MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.18G/4.95G [00:15<00:14, 52.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.23G/4.95G [00:15<00:09, 75.1MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.26G/4.95G [00:15<00:07, 94.6MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.29G/4.95G [00:15<00:05, 118MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.32G/4.95G [00:16<00:05, 123MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.35G/4.95G [00:16<00:04, 147MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.38G/4.95G [00:16<00:03, 170MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.41G/4.95G [00:16<00:02, 193MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.45G/4.95G [00:16<00:02, 212MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.48G/4.95G [00:16<00:02, 231MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.51G/4.95G [00:16<00:01, 244MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.54G/4.95G [00:17<00:01, 257MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.57G/4.95G [00:17<00:01, 264MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.60G/4.95G [00:17<00:01, 255MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.63G/4.95G [00:17<00:01, 260MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.67G/4.95G [00:17<00:01, 254MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.70G/4.95G [00:17<00:00, 263MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.73G/4.95G [00:17<00:00, 273MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.76G/4.95G [00:17<00:00, 276MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.80G/4.95G [00:17<00:00, 290MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.84G/4.95G [00:18<00:00, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.88G/4.95G [00:18<00:00, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.91G/4.95G [00:18<00:00, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.95G/4.95G [00:18<00:00, 268MB/s]\n",
            "Downloading shards:  67% 2/3 [00:38<00:19, 19.15s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/3.80G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 31.5M/3.80G [00:00<00:14, 261MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 62.9M/3.80G [00:00<00:14, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 94.4M/3.80G [00:00<00:13, 272MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   3% 126M/3.80G [00:00<00:13, 279MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 157M/3.80G [00:00<00:12, 280MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   5% 199M/3.80G [00:00<00:12, 297MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 231M/3.80G [00:00<00:12, 288MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   7% 273M/3.80G [00:00<00:11, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 315M/3.80G [00:01<00:10, 318MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   9% 357M/3.80G [00:01<00:10, 323MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 398M/3.80G [00:01<00:10, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 440M/3.80G [00:01<00:10, 325MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 482M/3.80G [00:01<00:10, 331MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  14% 524M/3.80G [00:01<00:09, 338MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 566M/3.80G [00:01<00:09, 343MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 608M/3.80G [00:01<00:09, 341MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  17% 650M/3.80G [00:02<00:09, 340MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 692M/3.80G [00:02<00:09, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 734M/3.80G [00:02<00:08, 341MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  20% 776M/3.80G [00:02<00:08, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 818M/3.80G [00:02<00:08, 339MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 860M/3.80G [00:02<00:08, 336MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 902M/3.80G [00:02<00:08, 338MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 944M/3.80G [00:02<00:08, 336MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 986M/3.80G [00:03<00:08, 338MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 1.03G/3.80G [00:03<00:08, 331MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  28% 1.07G/3.80G [00:03<00:08, 333MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  29% 1.11G/3.80G [00:03<00:09, 282MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.15G/3.80G [00:03<00:08, 302MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 1.20G/3.80G [00:03<00:09, 267MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 1.23G/3.80G [00:03<00:09, 263MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 1.26G/3.80G [00:04<00:09, 263MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.29G/3.80G [00:04<00:09, 271MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 1.32G/3.80G [00:04<00:08, 279MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 1.35G/3.80G [00:04<00:08, 284MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 1.38G/3.80G [00:04<00:08, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 1.42G/3.80G [00:04<00:08, 294MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 1.45G/3.80G [00:04<00:07, 299MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  39% 1.49G/3.80G [00:04<00:07, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 1.52G/3.80G [00:04<00:07, 308MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 1.56G/3.80G [00:05<00:07, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 1.60G/3.80G [00:05<00:06, 315MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  43% 1.65G/3.80G [00:05<00:06, 318MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 1.69G/3.80G [00:05<00:06, 322MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 1.73G/3.80G [00:05<00:06, 322MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 1.77G/3.80G [00:05<00:06, 321MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 1.81G/3.80G [00:05<00:06, 324MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 1.86G/3.80G [00:05<00:05, 332MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 1.90G/3.80G [00:06<00:05, 337MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 1.94G/3.80G [00:06<00:05, 348MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  52% 1.98G/3.80G [00:06<00:05, 356MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 2.02G/3.80G [00:06<00:04, 362MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 2.07G/3.80G [00:06<00:05, 336MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 2.11G/3.80G [00:06<00:05, 338MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  57% 2.15G/3.80G [00:06<00:04, 337MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 2.19G/3.80G [00:06<00:04, 340MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.23G/3.80G [00:07<00:04, 348MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  60% 2.28G/3.80G [00:07<00:04, 337MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 2.32G/3.80G [00:07<00:04, 338MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.36G/3.80G [00:07<00:04, 340MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 2.40G/3.80G [00:07<00:04, 347MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 2.44G/3.80G [00:07<00:03, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 2.49G/3.80G [00:07<00:03, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 2.53G/3.80G [00:07<00:03, 350MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 2.57G/3.80G [00:07<00:03, 351MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  69% 2.61G/3.80G [00:08<00:03, 308MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 2.65G/3.80G [00:08<00:03, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 2.69G/3.80G [00:08<00:03, 327MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 2.74G/3.80G [00:08<00:03, 332MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 2.78G/3.80G [00:08<00:03, 334MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 2.82G/3.80G [00:08<00:02, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 2.86G/3.80G [00:08<00:02, 340MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  76% 2.90G/3.80G [00:09<00:02, 344MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 2.95G/3.80G [00:09<00:02, 345MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 2.99G/3.80G [00:09<00:02, 341MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  80% 3.03G/3.80G [00:09<00:02, 347MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.07G/3.80G [00:09<00:02, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  82% 3.11G/3.80G [00:09<00:02, 339MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 3.16G/3.80G [00:09<00:01, 337MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 3.20G/3.80G [00:09<00:01, 337MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 3.24G/3.80G [00:10<00:01, 330MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 3.28G/3.80G [00:10<00:02, 219MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 3.32G/3.80G [00:10<00:01, 244MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 3.37G/3.80G [00:10<00:01, 266MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 3.40G/3.80G [00:10<00:01, 274MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  91% 3.44G/3.80G [00:10<00:01, 286MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 3.48G/3.80G [00:10<00:01, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 3.52G/3.80G [00:11<00:00, 320MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  94% 3.57G/3.80G [00:11<00:00, 329MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 3.61G/3.80G [00:11<00:00, 330MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 3.65G/3.80G [00:11<00:00, 339MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 3.69G/3.80G [00:11<00:00, 342MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 3.73G/3.80G [00:11<00:00, 352MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 3.80G/3.80G [00:11<00:00, 320MB/s]\n",
            "Downloading shards: 100% 3/3 [00:50<00:00, 16.89s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:07<00:00,  2.66s/it]\n",
            "generation_config.json: 100% 314/314 [00:00<00:00, 2.21MB/s]\n",
            "tokenizer_config.json: 100% 1.74k/1.74k [00:00<00:00, 12.6MB/s]\n",
            "tokenizer.json: 100% 2.67M/2.67M [00:00<00:00, 10.1MB/s]\n",
            "special_tokens_map.json: 100% 557/557 [00:00<00:00, 4.66MB/s]\n",
            "adapter_model.safetensors: 100% 160M/160M [00:01<00:00, 80.7MB/s]\n",
            "2024-08-09 02:28:06.909628: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-09 02:28:06.930316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-09 02:28:06.955144: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-09 02:28:06.962718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-09 02:28:06.980737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-09 02:28:08.062384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-08-09T02:29:46+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-10d9e4bf-c498-4162-93c1-22659b33900a acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ],
      "source": [
        "!streamlit run --server.port 8000 app.py > /dev/null"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}